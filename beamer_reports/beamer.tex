% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8

\documentclass[aspectratio=169]{beamer}
\usetheme{Madrid}
\usecolortheme{whale}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{bm}
\usepackage{tikz}
\usepackage{physics}
\usepackage{algorithm}
\usepackage{algorithmic}

% Color definitions
\definecolor{myblue}{RGB}{0,114,178}
\definecolor{myred}{RGB}{213,94,0}
\definecolor{mygreen}{RGB}{0,158,115}

\title{Dynamic Regimes of Diffusion Models}
\subtitle{A Volumetric and Temporal Analysis}
\author{Janis Aiad \and Thomas Pouponneau \and Aurélien Arnoux}
\institute{EA Topics in ML \\ Ecole Polytechnique \\ \vspace{0.5cm} \small Based on: Biroli et al., Nature Communications 15.1 (2024)}
\date{\today}

\begin{document}

\begin{frame}
    \titlepage
    \vspace{-1cm}
    \begin{center}
        \footnotesize
        \begin{tabular}{p{0.9\textwidth}}
            \textbf{Reference:} \\
            @article\{Biroli\_2024, \\
            \hspace{0.3cm} title=\{Dynamical regimes of diffusion models\}, \\
            \hspace{0.3cm} journal=\{Nature Communications\}, \\
            \hspace{0.3cm} author=\{Biroli, Giulio and Bonnaire, Tony and de Bortoli, Valentin and Mézard, Marc\}, \\
            \hspace{0.3cm} year=\{2024\}, volume=\{15\}, number=\{1\} \\
            \}
        \end{tabular}
    \end{center}
\end{frame}

\begin{frame}{Outline}
    \tableofcontents
\end{frame}



\section{Introduction}


%% 30 s
\begin{frame}{Example}
    \begin{center}
        \fbox{\parbox{0.8\textwidth}{
            \centering
            \vspace{2cm}
            \includegraphics[width=0.7\textwidth]{cars diffusion.gif}
            \vspace{2cm}
        }}
    \end{center}
\end{frame}

%% 1 minute
\begin{frame}{Diffusion Models: Mathematical Foundations}
    \begin{itemize}
        \item Stochastic Differential Equation (SDE):
        \begin{equation}
            dx_t = -\frac{1}{2} x_t dt + \sqrt{2} dW_t
        \end{equation}
        
        \item Two key probability distributions:
        \begin{itemize}
            \item Empirical distribution (data): $p_t^e(x)$
            \item Underlying distribution (manifold): $p_t(x)$
        \end{itemize}
        
        \item Gaussian convolution transformation:
        \begin{equation}
            p_t(x) = \int dy \; p_0(y) \frac{e^{-(x-ye^{-t})^2/(2\sigma_t^2)}}{(2\pi\sigma_t^2)^{d/2}}
        \end{equation}
        where $\sigma_t^2 = 1-e^{-2t}$
    \end{itemize}
\end{frame}

%% 1 minute
\begin{frame}{Motivation}
    \begin{itemize}
        \item Key questions :
        \begin{itemize}
            \item Trends of process' distribution
            \item Regimes and behavior for long times
            \item How to determine optimal beginning/stopping times?
        \end{itemize}
    \end{itemize}
\end{frame}


%% 30 s
\begin{frame}{Hypothesis Foundations}
    \begin{itemize}
        \item Diffusion equation:
        \begin{equation}
            dx_t = -\frac{1}{2} x_t dt + \sqrt{2} dW_t
        \end{equation}
        
        \item Exact score hypothesis:
        \begin{equation}
            \nabla \log p_t(x) \approx \hat{\nabla} \log p_t(x)
        \end{equation}
        
        \item High dimensional space:
        \begin{equation}
            d \gg 1 \text{ (typically } 10^3-10^4\text{)}
        \end{equation}
    \end{itemize}
\end{frame}



%% 30 s
\begin{frame}{Goal}

    
    \begin{itemize}
        \item n (say 100) images from a huge dataset
        \item Two main critical times:
        \begin{itemize}
            \item $t_s$: Critical time for class separation (gender, lighting ...)
            \item $t_c$: Critical time for image selection
        \end{itemize}
    \end{itemize}
\end{frame}











\section{Speciation time : crafting your characteristics}

%% 2 minute
\begin{frame}{Critical Separation Time ($t_s$)}
    \begin{itemize}
        \item Covariance C $\approx$ Cov(samples) = clusters infos
        \item Represents when classes begin to appear
        \item Can be estimated by:
        \begin{equation}
            t_s \approx \frac{1}{2}\log(d)
        \end{equation}
        \item Simple dependence on dimension only
        \item Independent of number of samples $n$
    \end{itemize}
    
    \begin{center}
        \fbox{\parbox{0.8\textwidth}{
            \centering
            \vspace{2cm}
            [Image: Class separation visualization]
            \vspace{2cm}
        }}
    \end{center}
\end{frame}

%% 2 minute
\begin{frame}{Results on Synthetic Data}
    \begin{itemize}
        \item Multi-wall potentials
        \item In 1D/2D: clear observation of 2 critical times
        \item In higher dimensions: behavior confirms theoretical predictions
    \end{itemize}
    
    \begin{center}
        \fbox{\parbox{0.8\textwidth}{
            \centering
            \vspace{2cm}
            [Image: MNIST class separation visualization]
            \vspace{2cm}
        }}
    \end{center}
\end{frame}


%% 2 minute
\begin{frame}{Results on MNIST, remarks}
    \begin{itemize}
        \item Spectral estimate of $t_s$ consistent with the dataset
        \item Potential wall over classes = 
    \end{itemize}

    
    
    \begin{center}
        \fbox{\parbox{0.8\textwidth}{
            \centering
            \vspace{2cm}
            [Image: MNIST Linear accuracy as a function of time + theoretical predictions (with integral of erfc(x) + empirical potential given centroids ]
            \vspace{2cm}
        }}
    \end{center}
\end{frame}















\section{Collapse time : avoid memorization}


%% 1 minute
\begin{frame}{Critical Collapse Time ($t_c$)}
    \begin{itemize}

        \item Represents when distribution becomes too concentrated
        \item Strongly depends on samples/dimension ratio
        \item When small:
        \begin{equation}
            t_c \approx \frac{d}{\log n}
        \end{equation}
    \end{itemize}
    
    \begin{center}
        \fbox{\parbox{0.8\textwidth}{
            \centering
            \vspace{2cm}
            [Image: Collapse visualization of stopping between 2 images with CIFAR]
            \vspace{2cm}
        }}
    \end{center}
\end{frame}



%% 2 minute
\begin{frame}{Critical Collapse Time ($t_c$)}
\begin{itemize}
    \item Intuition : more data = more choice to memorize an image !
\end{itemize}
\begin{center}
        \fbox{\parbox{0.8\textwidth}{
            \centering
            \vspace{2cm}
            [Image: Collapse visualization of stopping when near but not exactly on a 2D point]
            \vspace{2cm}
        }}
    \end{center}
\end{frame}


%% 1 minute
\begin{frame}{The Volumetric Argument}
    \begin{itemize}
        \item Main idea - use the curse of dimensionality - mass concentrated not around a point
    
        \item Allow analysis without exact score depends on:
        \begin{itemize}
            \item $n$: number of samples
            \item $d$: data dimension
            \item Capacity of the model used to learn the score
        \end{itemize}
    \end{itemize}
\end{frame}

%% 1 minute
\begin{frame}{The Volumetric Argument}
    
    \begin{center}
        \fbox{\parbox{0.8\textwidth}{
            \centering
            \vspace{2cm}
            [Image: MNIST 2 images separation visualization]
            \vspace{2cm}
        }}
    \end{center}
\end{frame}










\section{Conclusion and materials}
%% 30 s
\begin{frame}{Regularization and Improvement}
    \begin{itemize}
        \item Inexact score  = reduce collapse
        \item Non-parametric identification of critical zones during training
        \item very recent results on manifolds (D matters)
    \end{itemize}
\end{frame}



%% 30 s
\begin{frame}{Practical Applications}
    \begin{itemize}
        \item Calculation of $t_c$ and $t_s$ for any new dataset
        \item Fast inference of pre-trained models (HuggingFace)
    \end{itemize}
\end{frame}

\section{What to remember}
%% 1 minute
\begin{frame}{Summary of Contributions}
    \begin{itemize}
        \item Volumetric argument applicable beyond the exact empirical score hypothesis
        \item Deep understanding of model behavior as a function of $n$ and $d$
    \end{itemize}
\end{frame}


%% 1 minute
\begin{frame}{Future Directions - Very trendy subject}
    \begin{itemize}
        \item Data : hierarchy - distinguishing collapse/speciation
        \item Autosimilar Timescale for score, 4 walls potential
        \item Flow matching: verify if it presents the same phenomena (cusps)
    \end{itemize}
    
    \begin{center}
        \fbox{\parbox{0.8\textwidth}{
            \centering
            \vspace{2cm}
            [Image: Hierarchical visualization with hierarchical_tikz + calculations]
            \vspace{2cm}
        }}
    \end{center}
\end{frame}



























\begin{frame}
    \centering
    \LARGE Thank you for your attention!
    
    \vspace{1cm}
    
    \large Questions?

    
    \begin{center}
        \fbox{\parbox{0.8\textwidth}{
            \centering
            \vspace{2cm}
            [Image: Better viz from the paper in tikz, with true generated data]
            \vspace{2cm}
        }}
    \end{center}

        
\end{frame}

\end{document} 














